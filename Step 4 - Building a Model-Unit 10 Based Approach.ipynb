{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/buildacourt.jpg\" alt=\"Drawing\" style=\"width: 438px;\"/><img src=\"images/luxurycourt.jpg\" alt=\"Drawing\" style=\"width: 492px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Building a Model - ATP Match Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import sklearn.model_selection\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "c0=sns.color_palette()[0]\n",
    "c1=sns.color_palette()[1]\n",
    "c2=sns.color_palette()[2]\n",
    "\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "def points_plot(ax, Xtr, Xte, ytr, yte, clf, mesh=True, colorscale=cmap_light, \n",
    "                cdiscrete=cmap_bold, alpha=0.1, psize=10, zfunc=False, predicted=False):\n",
    "    h = .02\n",
    "    X=np.concatenate((Xtr, Xte))\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "\n",
    "    #plt.figure(figsize=(10,6))\n",
    "    if zfunc:\n",
    "        p0 = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 0]\n",
    "        p1 = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        Z=zfunc(p0, p1)\n",
    "    else:\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    ZZ = Z.reshape(xx.shape)\n",
    "    if mesh:\n",
    "        plt.pcolormesh(xx, yy, ZZ, cmap=cmap_light, alpha=alpha, axes=ax)\n",
    "    if predicted:\n",
    "        showtr = clf.predict(Xtr)\n",
    "        showte = clf.predict(Xte)\n",
    "    else:\n",
    "        showtr = ytr\n",
    "        showte = yte\n",
    "    ax.scatter(Xtr[:, 0], Xtr[:, 1], c=showtr-1, cmap=cmap_bold, \n",
    "               s=psize, alpha=alpha,edgecolor=\"k\")\n",
    "    # and testing points\n",
    "    ax.scatter(Xte[:, 0], Xte[:, 1], c=showte-1, cmap=cmap_bold, \n",
    "               alpha=alpha, marker=\"s\", s=psize+10)\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    return ax,xx,yy\n",
    "\n",
    "def points_plot_prob(ax, Xtr, Xte, ytr, yte, clf, colorscale=cmap_light, \n",
    "                     cdiscrete=cmap_bold, ccolor=cm, psize=10, alpha=0.1):\n",
    "    ax,xx,yy = points_plot(ax, Xtr, Xte, ytr, yte, clf, mesh=False, \n",
    "                           colorscale=colorscale, cdiscrete=cdiscrete, \n",
    "                           psize=psize, alpha=alpha, predicted=True) \n",
    "    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=ccolor, alpha=.2, axes=ax)\n",
    "    cs2 = plt.contour(xx, yy, Z, cmap=ccolor, alpha=.6, axes=ax)\n",
    "    plt.clabel(cs2, fmt = '%2.1f', colors = 'k', fontsize=14, axes=ax)\n",
    "    return ax \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflog = pd.read_csv('data/results.csv')\n",
    "dflog = dflog.drop(['Unnamed: 0'], axis = 1)\n",
    "dflogtrain = pd.read_csv('data/test.csv')\n",
    "dflogtrain = dflogtrain.drop(['Unnamed: 0'], axis = 1)\n",
    "dflogtest = pd.read_csv('data/test.csv')\n",
    "dflogtest = dflogtest.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>match_duration</th>\n",
       "      <th>rank_dif</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>aces</th>\n",
       "      <th>double_faults</th>\n",
       "      <th>first_serves_in</th>\n",
       "      <th>first_serves_total</th>\n",
       "      <th>first_serve_points_won</th>\n",
       "      <th>first_serve_points_total</th>\n",
       "      <th>second_serve_points_won</th>\n",
       "      <th>second_serve_points_total</th>\n",
       "      <th>break_points_saved</th>\n",
       "      <th>break_points_serve_total</th>\n",
       "      <th>service_points_won</th>\n",
       "      <th>service_points_total</th>\n",
       "      <th>first_serve_return_won</th>\n",
       "      <th>first_serve_return_total</th>\n",
       "      <th>second_serve_return_won</th>\n",
       "      <th>second_serve_return_total</th>\n",
       "      <th>break_points_converted</th>\n",
       "      <th>break_points_return_total</th>\n",
       "      <th>service_games_played</th>\n",
       "      <th>return_games_played</th>\n",
       "      <th>return_points_won</th>\n",
       "      <th>return_points_total</th>\n",
       "      <th>total_points_won</th>\n",
       "      <th>total_points_total</th>\n",
       "      <th>player_id</th>\n",
       "      <th>match_score_tiebreaks</th>\n",
       "      <th>sets_won</th>\n",
       "      <th>games_won</th>\n",
       "      <th>tiebreaks_won</th>\n",
       "      <th>rank_number</th>\n",
       "      <th>ranking_points</th>\n",
       "      <th>ace_pct</th>\n",
       "      <th>df_pct</th>\n",
       "      <th>srv_pts_pct</th>\n",
       "      <th>rtn_pts_pct</th>\n",
       "      <th>brk_pts_pct</th>\n",
       "      <th>points_won_pct</th>\n",
       "      <th>win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1991-354-a028-c113</td>\n",
       "      <td>66.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>1990</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>a028</td>\n",
       "      <td>62 64</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>79.166667</td>\n",
       "      <td>41.071429</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>58.653846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1991-354-a028-c113</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>1990</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>c113</td>\n",
       "      <td>62 64</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.357143</td>\n",
       "      <td>5.357143</td>\n",
       "      <td>58.928571</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.346154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1991-354-b040-c260</td>\n",
       "      <td>147.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>1990</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>b040</td>\n",
       "      <td>76(5) 76(8)</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.191489</td>\n",
       "      <td>2.127660</td>\n",
       "      <td>61.702128</td>\n",
       "      <td>39.622642</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1991-354-b040-c260</td>\n",
       "      <td>147.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>1990</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>c260</td>\n",
       "      <td>76(5) 76(8)</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.773585</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>60.377358</td>\n",
       "      <td>38.297872</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1991-354-b040-m048</td>\n",
       "      <td>68.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>1990</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>b040</td>\n",
       "      <td>63 62</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.081633</td>\n",
       "      <td>2.040816</td>\n",
       "      <td>63.265306</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>58.653846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             match_id  match_duration  rank_dif        date  year  month  day  aces  double_faults  first_serves_in  first_serves_total  first_serve_points_won  first_serve_points_total  second_serve_points_won  second_serve_points_total  break_points_saved  break_points_serve_total  service_points_won  service_points_total  first_serve_return_won  first_serve_return_total  second_serve_return_won  second_serve_return_total  break_points_converted  break_points_return_total  \\\n",
       "0  1991-354-a028-c113            66.0      51.0  1990-12-31  1990     12   31   2.0            1.0             29.0                48.0                    26.0                      29.0                     12.0                       19.0                 0.0                       0.0                38.0                  48.0                    15.0                      42.0                      8.0                       14.0                     3.0                       12.0   \n",
       "1  1991-354-a028-c113            66.0     -51.0  1990-12-31  1990     12   31   3.0            3.0             42.0                56.0                    27.0                      42.0                      6.0                       14.0                 9.0                      12.0                33.0                  56.0                     3.0                      29.0                      7.0                       19.0                     0.0                        0.0   \n",
       "2  1991-354-b040-c260           147.0     -59.0  1990-12-31  1990     12   31   3.0            2.0             56.0                94.0                    37.0                      56.0                     21.0                       38.0                 3.0                       6.0                58.0                  94.0                    30.0                      72.0                     12.0                       34.0                     3.0                       15.0   \n",
       "3  1991-354-b040-c260           147.0      59.0  1990-12-31  1990     12   31   4.0            1.0             72.0               106.0                    42.0                      72.0                     22.0                       34.0                12.0                      15.0                64.0                 106.0                    19.0                      56.0                     17.0                       38.0                     3.0                        6.0   \n",
       "4  1991-354-b040-m048            68.0      40.0  1990-12-31  1990     12   31   2.0            1.0             37.0                49.0                    25.0                      37.0                      6.0                       12.0                 4.0                       6.0                31.0                  49.0                    24.0                      47.0                      6.0                        8.0                     6.0                       11.0   \n",
       "\n",
       "   service_games_played  return_games_played  return_points_won  return_points_total  total_points_won  total_points_total player_id match_score_tiebreaks  sets_won  games_won  tiebreaks_won  rank_number  ranking_points   ace_pct    df_pct  srv_pts_pct  rtn_pts_pct  brk_pts_pct  points_won_pct  win  \n",
       "0                   9.0                  9.0               23.0                 56.0              61.0               104.0      a028                 62 64         2         12              0         64.0             0.0  4.166667  2.083333    79.166667    41.071429    25.000000       58.653846    1  \n",
       "1                   9.0                  9.0               10.0                 48.0              43.0               104.0      c113                 62 64         0          6              0        115.0             0.0  5.357143  5.357143    58.928571    20.833333     0.000000       41.346154    0  \n",
       "2                  12.0                 12.0               42.0                106.0             100.0               200.0      b040           76(5) 76(8)         2         14              2         80.0             0.0  3.191489  2.127660    61.702128    39.622642    20.000000       50.000000    1  \n",
       "3                  12.0                 12.0               36.0                 94.0             100.0               200.0      c260           76(5) 76(8)         0         12              0         21.0             0.0  3.773585  0.943396    60.377358    38.297872    50.000000       50.000000    0  \n",
       "4                   8.0                  9.0               30.0                 55.0              61.0               104.0      b040                 63 62         2         12              0         80.0             0.0  4.081633  2.040816    63.265306    54.545455    54.545455       58.653846    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dflog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['aces','ace_pct','double_faults','df_pct','first_serves_in','srv_pts_pct','first_serve_points_won',\n",
    "            'return_points_won','rtn_pts_pct','break_points_converted','brk_pts_pct','total_points_won','points_won_pct']\n",
    "features1 = ['rank_dif','aces','double_faults','first_serves_in', 'first_serve_points_won','second_serve_points_won',\n",
    "            'break_points_saved','service_points_won','first_serve_return_won','second_serve_return_won',\n",
    "            'break_points_converted','service_games_played','return_games_played','return_points_won',\n",
    "            'total_points_won','games_won','ace_pct','df_pct','srv_pts_pct','rtn_pts_pct','brk_pts_pct','points_won_pct']\n",
    "predictor = ['win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9514536665077961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into a training and test set.\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(dflog[['aces','ace_pct','double_faults','df_pct','first_serves_in','srv_pts_pct','first_serve_points_won',\n",
    "            'return_points_won','rtn_pts_pct','break_points_converted','brk_pts_pct','total_points_won','points_won_pct']].values, \n",
    "                                              (dflog.win == 1).values,random_state=5)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(Xlr, ylr)\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(Xtestlr), ytestlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def cv_score(clf, x, y, score_func=accuracy_score):\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(x): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y[train]) # fit\n",
    "        result += score_func(clf.predict(x[test]), y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9507274104191481\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "score = cv_score(clf, Xlr, ylr)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for this model is: 0.9364335894983608\n"
     ]
    }
   ],
   "source": [
    "#the grid of parameters to search over\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "\n",
    "# your turn\n",
    "scr=[]\n",
    "\n",
    "for value in Cs:\n",
    "    #Creating Logistic Regression object with different C values from above list.\n",
    "    clf1 = LogisticRegression(C=value)\n",
    "    # Fit the model on the trainng data.\n",
    "    clf1.fit(Xlr, ylr)\n",
    "    score = cv_score(clf1, Xlr, ylr)\n",
    "    #print(\"C value: \" + str(value) + \" LogisticRegression Score: \" + str(score))\n",
    "    scr.append(score)\n",
    "\n",
    "#average score for this model using the cv_score function only on the training set (Xlr, ylr) \n",
    "avg = np.mean(scr)\n",
    "print(\"Average Score for this model is: \" + str(avg))\n",
    "\n",
    "#picking the C with the highest average score\n",
    "\n",
    "diff=(avg-scr)\n",
    "df = pd.DataFrame(np.column_stack([Cs, scr, diff]), columns=['Cval', 'Score', 'diff'])\n",
    "#df.max()\n",
    "\n",
    "# So C value is 0.001 for highest average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8814598131891469"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression on the test data using C value from training data\n",
    "#Creating Logistic Regression object with different C values from above list.\n",
    "clf2 = LogisticRegression(C=0.001)\n",
    "# Fit the model on the trainng data.\n",
    "clf1.fit(Xlr, ylr)\n",
    "score = cv_score(clf2, Xtestlr, ytestlr)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " {'C': 100},\n",
       " 0.9516201024337472,\n",
       " {'mean_fit_time': array([0.70859528, 0.92814975, 3.16363297, 3.91326418, 3.96339998,\n",
       "         3.99690366]),\n",
       "  'std_fit_time': array([0.04754539, 0.01689939, 0.34789144, 0.24954856, 0.33262758,\n",
       "         0.26405843]),\n",
       "  'mean_score_time': array([0.00378447, 0.00276432, 0.00279317, 0.00319848, 0.00299211,\n",
       "         0.00258684]),\n",
       "  'std_score_time': array([0.00041251, 0.00073926, 0.00074651, 0.00039595, 0.00063083,\n",
       "         0.00049621]),\n",
       "  'param_C': masked_array(data=[0.0001, 0.001, 0.1, 1, 10, 100],\n",
       "               mask=[False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'C': 0.0001},\n",
       "   {'C': 0.001},\n",
       "   {'C': 0.1},\n",
       "   {'C': 1},\n",
       "   {'C': 10},\n",
       "   {'C': 100}],\n",
       "  'split0_test_score': array([0.87366191, 0.88497182, 0.94050006, 0.94976737, 0.95067519,\n",
       "         0.95075084]),\n",
       "  'split1_test_score': array([0.87665015, 0.88871657, 0.9412944 , 0.95037258, 0.9512804 ,\n",
       "         0.95146953]),\n",
       "  'split2_test_score': array([0.87460756, 0.88614442, 0.94137005, 0.95044824, 0.95131823,\n",
       "         0.95124258]),\n",
       "  'split3_test_score': array([0.87385104, 0.88448008, 0.94099179, 0.95090214, 0.95271778,\n",
       "         0.95286908]),\n",
       "  'split4_test_score': array([0.8770191 , 0.88904861, 0.94276527, 0.9511254 , 0.95203329,\n",
       "         0.95176849]),\n",
       "  'mean_test_score': array([0.87515792, 0.88667226, 0.94138429, 0.95052314, 0.95160497,\n",
       "         0.9516201 ]),\n",
       "  'std_test_score': array([0.00140993, 0.00188689, 0.00075515, 0.00047028, 0.0007034 ,\n",
       "         0.00070751]),\n",
       "  'rank_test_score': array([6, 5, 4, 3, 2, 1])})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "clfl2=LogisticRegression()\n",
    "parameters = {\"C\": [0.0001, 0.001, 0.1, 1, 10, 100]}\n",
    "fitmodel = GridSearchCV(clfl2, param_grid=parameters, cv=5, scoring=\"accuracy\")\n",
    "fitmodel.fit(Xlr, ylr)\n",
    "fitmodel.best_estimator_, fitmodel.best_params_, fitmodel.best_score_, fitmodel.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9521799323664919"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfl2=LogisticRegression(C=fitmodel.best_params_['C'])\n",
    "clfl2.fit(Xlr, ylr)\n",
    "ypred2=clfl2.predict(Xtestlr)\n",
    "accuracy_score(ypred2, ytestlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=5):\n",
    "    gs = sklearn.model_selection.GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
    "    gs.fit(Xtrain, ytrain)\n",
    "    print(\"BEST PARAMS\", gs.best_params_)\n",
    "    best = gs.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def do_classify(clf, parameters, indf, featurenames, targetname, target1val, standardize=False, train_size=0.8):\n",
    "    subdf=indf[featurenames]\n",
    "    if standardize:\n",
    "        subdfstd=(subdf - subdf.mean())/subdf.std()\n",
    "    else:\n",
    "        subdfstd=subdf\n",
    "    X=subdfstd.values\n",
    "    y=(indf[targetname].values==target1val)*1\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=train_size)\n",
    "    clf = cv_optimize(clf, parameters, Xtrain, ytrain)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print(\"Accuracy on training data: {:0.2f}\".format(training_accuracy))\n",
    "    print(\"Accuracy on test data:     {:0.2f}\".format(test_accuracy))\n",
    "    return clf, Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>match_duration</th>\n",
       "      <th>rank_dif</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>aces</th>\n",
       "      <th>double_faults</th>\n",
       "      <th>first_serves_in</th>\n",
       "      <th>first_serves_total</th>\n",
       "      <th>first_serve_points_won</th>\n",
       "      <th>first_serve_points_total</th>\n",
       "      <th>second_serve_points_won</th>\n",
       "      <th>second_serve_points_total</th>\n",
       "      <th>break_points_saved</th>\n",
       "      <th>break_points_serve_total</th>\n",
       "      <th>service_points_won</th>\n",
       "      <th>service_points_total</th>\n",
       "      <th>first_serve_return_won</th>\n",
       "      <th>first_serve_return_total</th>\n",
       "      <th>second_serve_return_won</th>\n",
       "      <th>second_serve_return_total</th>\n",
       "      <th>break_points_converted</th>\n",
       "      <th>break_points_return_total</th>\n",
       "      <th>service_games_played</th>\n",
       "      <th>return_games_played</th>\n",
       "      <th>return_points_won</th>\n",
       "      <th>return_points_total</th>\n",
       "      <th>total_points_won</th>\n",
       "      <th>total_points_total</th>\n",
       "      <th>player_id</th>\n",
       "      <th>match_score_tiebreaks</th>\n",
       "      <th>sets_won</th>\n",
       "      <th>games_won</th>\n",
       "      <th>tiebreaks_won</th>\n",
       "      <th>rank_number</th>\n",
       "      <th>ranking_points</th>\n",
       "      <th>ace_pct</th>\n",
       "      <th>df_pct</th>\n",
       "      <th>srv_pts_pct</th>\n",
       "      <th>rtn_pts_pct</th>\n",
       "      <th>brk_pts_pct</th>\n",
       "      <th>points_won_pct</th>\n",
       "      <th>win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1991-354-a028-c113</td>\n",
       "      <td>66.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>1990</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>a028</td>\n",
       "      <td>62 64</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>79.166667</td>\n",
       "      <td>41.071429</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>58.653846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1991-354-a028-c113</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>1990</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>c113</td>\n",
       "      <td>62 64</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.357143</td>\n",
       "      <td>5.357143</td>\n",
       "      <td>58.928571</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.346154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1991-354-b040-c260</td>\n",
       "      <td>147.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>1990</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>b040</td>\n",
       "      <td>76(5) 76(8)</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.191489</td>\n",
       "      <td>2.127660</td>\n",
       "      <td>61.702128</td>\n",
       "      <td>39.622642</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1991-354-b040-c260</td>\n",
       "      <td>147.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>1990</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>c260</td>\n",
       "      <td>76(5) 76(8)</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.773585</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>60.377358</td>\n",
       "      <td>38.297872</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1991-354-b040-m048</td>\n",
       "      <td>68.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>1990</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>b040</td>\n",
       "      <td>63 62</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.081633</td>\n",
       "      <td>2.040816</td>\n",
       "      <td>63.265306</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>58.653846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             match_id  match_duration  rank_dif        date  year  month  day  aces  double_faults  first_serves_in  first_serves_total  first_serve_points_won  first_serve_points_total  second_serve_points_won  second_serve_points_total  break_points_saved  break_points_serve_total  service_points_won  service_points_total  first_serve_return_won  first_serve_return_total  second_serve_return_won  second_serve_return_total  break_points_converted  break_points_return_total  \\\n",
       "0  1991-354-a028-c113            66.0      51.0  1990-12-31  1990     12   31   2.0            1.0             29.0                48.0                    26.0                      29.0                     12.0                       19.0                 0.0                       0.0                38.0                  48.0                    15.0                      42.0                      8.0                       14.0                     3.0                       12.0   \n",
       "1  1991-354-a028-c113            66.0     -51.0  1990-12-31  1990     12   31   3.0            3.0             42.0                56.0                    27.0                      42.0                      6.0                       14.0                 9.0                      12.0                33.0                  56.0                     3.0                      29.0                      7.0                       19.0                     0.0                        0.0   \n",
       "2  1991-354-b040-c260           147.0     -59.0  1990-12-31  1990     12   31   3.0            2.0             56.0                94.0                    37.0                      56.0                     21.0                       38.0                 3.0                       6.0                58.0                  94.0                    30.0                      72.0                     12.0                       34.0                     3.0                       15.0   \n",
       "3  1991-354-b040-c260           147.0      59.0  1990-12-31  1990     12   31   4.0            1.0             72.0               106.0                    42.0                      72.0                     22.0                       34.0                12.0                      15.0                64.0                 106.0                    19.0                      56.0                     17.0                       38.0                     3.0                        6.0   \n",
       "4  1991-354-b040-m048            68.0      40.0  1990-12-31  1990     12   31   2.0            1.0             37.0                49.0                    25.0                      37.0                      6.0                       12.0                 4.0                       6.0                31.0                  49.0                    24.0                      47.0                      6.0                        8.0                     6.0                       11.0   \n",
       "\n",
       "   service_games_played  return_games_played  return_points_won  return_points_total  total_points_won  total_points_total player_id match_score_tiebreaks  sets_won  games_won  tiebreaks_won  rank_number  ranking_points   ace_pct    df_pct  srv_pts_pct  rtn_pts_pct  brk_pts_pct  points_won_pct  win  \n",
       "0                   9.0                  9.0               23.0                 56.0              61.0               104.0      a028                 62 64         2         12              0         64.0             0.0  4.166667  2.083333    79.166667    41.071429    25.000000       58.653846    1  \n",
       "1                   9.0                  9.0               10.0                 48.0              43.0               104.0      c113                 62 64         0          6              0        115.0             0.0  5.357143  5.357143    58.928571    20.833333     0.000000       41.346154    0  \n",
       "2                  12.0                 12.0               42.0                106.0             100.0               200.0      b040           76(5) 76(8)         2         14              2         80.0             0.0  3.191489  2.127660    61.702128    39.622642    20.000000       50.000000    1  \n",
       "3                  12.0                 12.0               36.0                 94.0             100.0               200.0      c260           76(5) 76(8)         0         12              0         21.0             0.0  3.773585  0.943396    60.377358    38.297872    50.000000       50.000000    0  \n",
       "4                   8.0                  9.0               30.0                 55.0              61.0               104.0      b040                 63 62         2         12              0         80.0             0.0  4.081633  2.040816    63.265306    54.545455    54.545455       58.653846    1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dflog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 10}\n",
      "Accuracy on training data: 0.95\n",
      "Accuracy on test data:     0.95\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           dflog, ['aces','ace_pct','double_faults','df_pct','first_serves_in','srv_pts_pct','first_serve_points_won',\n",
    "            'return_points_won','rtn_pts_pct','break_points_converted','brk_pts_pct','total_points_won','points_won_pct'], 'win',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 2 features per sample; expecting 13",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2672d5ea5904>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpoints_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtrain_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtest_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-f6c5890e0ad0>\u001b[0m in \u001b[0;36mpoints_plot\u001b[1;34m(ax, Xtr, Xte, ytr, yte, clf, mesh, colorscale, cdiscrete, alpha, psize, zfunc, predicted)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mZ\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mzfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[0mZZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmesh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \"\"\"\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 270\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2 features per sample; expecting 13"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''plt.figure()\n",
    "ax=plt.gca()\n",
    "points_plot(ax, Xtrain_l, Xtest_l, ytrain_l, ytest_l, clf_l, alpha=0.2);'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.23057585e-03, 9.90769424e-01],\n",
       "       [9.32992525e-01, 6.70074749e-02],\n",
       "       [1.23118673e-01, 8.76881327e-01],\n",
       "       ...,\n",
       "       [3.47065461e-01, 6.52934539e-01],\n",
       "       [9.99922584e-01, 7.74157488e-05],\n",
       "       [4.91182710e-03, 9.95088173e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l.predict_proba(Xtest_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 2 features per sample; expecting 13",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4623a93fcfe6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpoints_plot_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtrain_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtest_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-f6c5890e0ad0>\u001b[0m in \u001b[0;36mpoints_plot_prob\u001b[1;34m(ax, Xtr, Xte, ytr, yte, clf, colorscale, cdiscrete, ccolor, psize, alpha)\u001b[0m\n\u001b[0;32m     65\u001b[0m     ax,xx,yy = points_plot(ax, Xtr, Xte, ytr, yte, clf, mesh=False, \n\u001b[0;32m     66\u001b[0m                            \u001b[0mcolorscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolorscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcdiscrete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcdiscrete\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                            psize=psize, alpha=alpha, predicted=True) \n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-f6c5890e0ad0>\u001b[0m in \u001b[0;36mpoints_plot\u001b[1;34m(ax, Xtr, Xte, ytr, yte, clf, mesh, colorscale, cdiscrete, alpha, psize, zfunc, predicted)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mZ\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mzfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[0mZZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmesh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \"\"\"\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 270\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2 features per sample; expecting 13"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "points_plot_prob(ax, Xtrain_l, Xtest_l, ytrain_l, ytest_l, clf_l, psize=20, alpha=0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
